knitr::opts_chunk$set(include  = TRUE)
# Downloading the website
website <- xml2::read_html("https://pubmed.ncbi.nlm.nih.gov/?term=sars-cov-2")
# Finding the counts
counts <- xml2::xml_find_first(website, "/html/body/main/div[9]/div[2]/div[2]/div[1]/div[1]/span")
# Turning it into text
counts <- as.character(counts)
# Extracting the data using regex
stringr::str_extract(counts, "[0-9,]+")
library(httr)
query_ids <- GET(
url   = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi",
query = list(
db = 'pubmed',
term = 'covid19 canada',
retmax = 1000
)
)
# Extracting the content of the response of GET
ids <- httr::content(query_ids)
# Turn the result into a character vector
ids <- as.character(ids)
# Find all the ids
ids <- unlist(stringr::str_extract_all(ids, "<Id>[0-9]+</Id>"))
# Remove all the leading and trailing <Id> </Id>. Make use of "|"
ids <- stringr::str_remove_all(ids, "<Id>|</Id>")
ids <- head(ids, 300)
publications <- GET(
url   = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi",
query = list(
db = 'pubmed',
id = paste(ids, collapse = ","),
retmax = 1000,
rettype = 'abstract'
)
)
# Turning the output into character vector
#publications <- httr::content(publications)
#publications_txt <- as.character(publications)
publications
institution <- stringr::str_extract_all(
publications_txt,
"University\\s+of\\s+[[:alpha:]]+ | [[:alpha:]]+\\s+Institute\\s+of\\s+[[:alpha:]]+"
)
publications <- GET(
url   = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi",
query = list(
db = 'pubmed',
id = paste(ids, collapse = ","),
retmax = 1000,
rettype = 'abstract'
)
)
# Turning the output into character vector
publications <- httr::content(publications)
publications_txt <- as.character(publications)
institution <- stringr::str_extract_all(
publications_txt,
"University\\s+of\\s+[[:alpha:]]+ | [[:alpha:]]+\\s+Institute\\s+of\\s+[[:alpha:]]+"
)
institution <- unlist(institution)
table(institution)
schools_and_deps <- str_extract_all(
abstracts_txt,
"School\\s+of\\s+[[:alpha:]]+ | Department\\s+of\\s+[[:alpha:]]++"
)
schools_and_deps <- stringr::str_extract_all(
abstracts_txt,
"School\\s+of\\s+[[:alpha:]]+ | Department\\s+of\\s+[[:alpha:]]++"
)
institution <- stringr::str_extract_all(
publications_txt,
"University\\s+of\\s+[[:alpha:]]+ | [[:alpha:]\\s]+\\s+Institute\\s+of\\s+[[:alpha:]]+"
)
institution <- unlist(institution)
table(institution)
schools_and_deps <- stringr::str_extract_all(
publications_txt,
"School\\s+of\\s+[[:alpha:]]+ | Department\\s+of\\s+[[:alpha:]]++"
)
table(schools_and_deps)
institution <- stringr::str_extract_all(
publications_txt,
"University\\s+of\\s+[[:alpha:]\\s]+ | [[:alpha:]\\s]+\\s+Institute\\s+of\\s+[[:alpha:]]+"
)
institution <- unlist(institution)
table(institution)
schools_and_deps <- stringr::str_extract_all(
publications_txt,
"School\\s+of\\s+[[:alpha:]\\s]+ | Department\\s+of\\s+[[:alpha:]\\s]++"
)
table(schools_and_deps)
institution <- stringr::str_extract_all(
publications_txt,
"University\\s+of\\s+[[:alpha:].*]+ | [[:alpha:].*]+\\s+Institute\\s+of\\s+[[:alpha:].*]+"
)
institution <- unlist(institution)
table(institution)
institution <- stringr::str_extract_all(
publications_txt,
"University\\s+of\\s+[[:alpha:]]+ | [[:alpha:]]+\\s+Institute\\s+of\\s+[[:alpha:]]+"
)
institution <- unlist(institution)
table(institution)
institution <- stringr::str_extract_all(
publications_txt,
"University\\s+of\\s+[[:alpha:]]+ | [[:alpha:]]+\\s+Institute\\s+of\\s+[[:alpha:]]+"
)
institution <- unlist(institution)
table(institution)
pub_char_list <- xml2::xml_children(publications)
pub_char_list <- sapply(pub_char_list, as.character)
pub_char_list
